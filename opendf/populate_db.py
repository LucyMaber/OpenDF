"""
populate DB from SMCalFlow dialogues.
"""

# Take SIMPLIFIED dialogs, and try to create the necessary database entries so that the dialog will run -
#   i.e. that the system's answers will be consistent with the answers in the dataset.
# Notes:
#  - as a start, we do this for each dialog separately! not enforcing consistency between dialogs!
#  - fill the minimum necessary
#  - there is no unique correct answer

# next steps
#   - compare a run to the one in the dataset (how?)
#   - modify the dataset to be consistent with our implementation

# Note - to avoid any copyright issues, we EXCLUSIVELY write programmatic processing of the original dataset -
#        i.e. the starting point is the original dataset, and any transformed version is generated by a program.

# to run this from the command line (assuming running from the repository's root directory) , use:
# PYTHONPATH=$(pwd) python opendf/populate_db.py -i train/valid -c resources/populate_smcalflow_config.yaml workdir


import json
import argparse

from opendf.graph.constr_graph import construct_graph, check_constr_graph
from opendf.graph.eval import evaluate_graph, check_dangling_nodes
from opendf.graph.node_factory import NodeFactory
from opendf.defs import *
from opendf.graph.dialog_context import DialogContext
from opendf.utils.arg_utils import add_environment_option
from opendf.utils.io import load_jsonl_file
from opendf.utils.utils import to_list
from opendf.graph.transform_graph import trans_graph
from opendf.graph.draw_graph import draw_all_graphs
from opendf.misc.populate_utils import init_db, get_all_db_events
from opendf.applications.smcalflow.domain import get_stub_data_from_json
from opendf.exceptions import re_raise_exc
from opendf.exceptions.df_exception import DFException
from opendf.misc.populate_utils import parse_agent_txt, norm2
import yaml
from random import randint, seed, random

seed(100)

logger = logging.getLogger(__name__)




class PopContext(DialogContext):
    def __init__(self):
        super(PopContext, self).__init__()
        self.agent_context = None  # pointer to agent context (needed?)
        self.agent_words = []
        self.agent_templs = []
        self.agent_vals = []
        # self.templates = None
        self.user_vals = []
        self.db_people = None  # temp storage of db stub data
        self.db_events = None
        self.db_places = None
        self.user_txt = None
        self.agent_txt = None
        self.populated_events = []  # keep the id's of recipients which were added by populate (i.e. not by create)
        self.init_stub_file = None
        # self.ag_pos = []  # elements which the agent implied are valid
        # self.ag_neg = []  # elements about which the agent complained
        # self.link_ents = []

    def clear_pop_context(self):
        self.agent_context = None  # pointer to agent context (needed?)
        self.agent_words = []
        self.agent_templs = []
        self.agent_vals = []
        # self.templates = None
        self.user_vals = []
        self.db_people = None  # temp storage of db stub data
        self.db_events = None
        self.db_places = None
        self.user_txt = None
        self.agent_txt = None
        self.populated_events = []  # keep the id's of recipients which were added by populate (i.e. not by create)
        self.init_stub_file = None
        # self.ag_pos = []  # elements which the agent implied are valid
        # self.ag_neg = []  # elements about which the agent complained
        # self.link_ents = []
        # self.link_res = []


def conv_obj(objs):
    return [o if isinstance(o, str) else o.show() for o in objs]


# compare execution results of two runs, each represented by a d_context - initial implementation
# TODO This function will also be used to compare execution of ground-truth Pexp and translated NL->Pexp
# one possible way to compare is to look only at the response of the agent - ignore the internal structure
#   (this ignores the source of the error - we may get a wrong execution which generates a correct answer -
#     error may manifest in later turns!)
# - focus on the last turns
# - look at result pointers
# - see that object id's match (for now, just that the same object id appears "somewhere" in the same turn's results)
# - see that the same values appear in results of specific functions
# mode - to remind that there can be multiple modes of comparison
def compare_graph_exec(ctx1, ctx2, evs1=None, evs2=None, mode=None):
    evs1 = evs1 if evs1 else []
    evs2 = evs2 if evs2 else []
    if len(evs1) != len(evs2) or not all([i in evs2 for i in evs1]):
        print('      MISmatched events')
        print(evs1)
        print('   :::')
        print(evs2)
        return False
    turn1, exc1, msg1 = ctx1.get_exec_status()
    turn2, exc2, msg2 = ctx2.get_exec_status()
    if turn1!=turn2 or (exc1 and not exc2) or (exc2 and not exc1):
        return False
    if exc1:  # both have exceptions
        # n1, n2 = exc1[-1][0], exc2[-1][0]
        e1, e2 = exc1[-1], exc2[-1]
        o1, o2 = e1.objects if e1.objects else [], e2.objects if e2.objects else []
        o1, o2 = conv_obj(o1), conv_obj(o2)
        ok = len(o1)==len(o2) and all([o in e2.objects for o in e1.objects])
        return ok

    if (msg1 and not msg2) or (msg2 and not msg1):
        return False
    if msg1:  # both have messages
        n1, n2 = msg1[-1].node, msg2[-1].node
    if msg1 and n1.typename() == n2.typename() == 'Yield':
        m1 = n1.result.yield_msg()
        s1, o1 = m1.text, m1.objects  # y1 if isinstance(y1, tuple) and len(y1)==2 else (y1, ['999'])  # temp check, until all yields return objs
        m2 = n2.result.yield_msg()
        s2, o2 = ms.text, m2.objects  #y2 if isinstance(y2, tuple) and len(y2)==2 else (y2, ['999'])  # temp check, until all yields return objs
        o1, o2 = conv_obj(o1), conv_obj(o2)
        ok = all([o in o2 for o in o1])
        # print(o1)
        # print(o2)
        if True:
            for o in o1:
                if o in o2:
                    print('      matched: %s' % o)
                else:
                    print('      MISmatched: %s' % o)
        return ok
    return False

# def link_person(g, n1, n2, ent_node):
#     nds = g.topological_order()
#     prs = g.get_nodes_of_typ(nds, 'PersonName')
#     n1 = n1.lower()
#     n2 = n2.lower() if n2 else None
#     for p in prs:
#         nm = p.dat.lower()
#         if nm:
#             m = nm.split()
#             m1, m2 = (m[0], m[1]) if len(m)>1 else (m[0], None)
#             if m2:  # user gave (at least) 2 names (first+last)
#                 if n2 and n1 in nm and n2 in nm:
#                     return p, '%s %s' % (n1, n2), ent_node
#             else:  # user gave just one name
#                 if n1 in nm or (n2 and n2 in nm):
#                     return p, '%s %s' % (n1, n2), ent_node
#     return []

# TODO - entity linking?

# TO DO:
#  - entity linking!!
#    - link entities in agent answer (and context) to entities (nodes) in d_context!
#      - maybe also link to results? or to functions for which the agent enities are the result?
#         - e.g. link an event to FindEvents?
#    - needed for: ground truth checking (found right object), augmentation...
# should this logic be distributed to the nodes?
# def parse_agent_answer(txt, templates, grph, vals, dctx, actx):
#     pos, neg, elink, rlink = [], [], [], []
#     awords, atmpl, avals = match_templates(txt, templates)
#
#     m = re.match(r"No, I found no events with (\w+) (\w+)", txt)
#     if m:
#         pos = 'Recipient(firstName=%s, lastName=%s)' % (m[1], m[2])
#         neg = 'Event?(attendees=Attendee?(recipient=%s))' % pos
#         elink = link_person(grph, m[1], m[2], pos)
#
#     pos, neg = to_list(pos), to_list(neg)
#     if pos or neg:
#         pos = [Node.call_construct(p, actx)[0] for p in pos]
#         neg = [Node.call_construct(n, actx)[0] for n in neg]
#     return pos, neg, to_list(elink), to_list(rlink)  # TO DO - return linking

# since changed to CFG parser, no more need for getting entities from user turn?
def add_turn_entities(utxt, atxt, grph, dctx):  # , actx):  # templates,
    # vals = []
    # nn = grph.topological_order()
    # for n in nn:
    #     if n.typename() in node_fact.leaf_types and n.dat is not None:
    #         # vals.append('%s=%s' % (n.typename(), re.sub(' ', '_', '%s' % n.dat)))
    #         vals.append((n.typename(), ('%s' % n.dat).split()))
    # awords, atmpl, avals = match_templates(atxt, templates)
    # dctx.agent_context = actx
    # dctx.agent_words = awords
    # dctx.agent_templs = atmpl
    # dctx.agent_vals = avals
    # dctx.user_vals = vals
    dctx.agent_txt = atxt
    dctx.user_txt = utxt
    # store in context...
    # TO DO - add linking
    # pos, neg, elink, rlink = parse_agent_answer(agent_txt, templates, gl, vals, d_context, a_context)
    # d_context.ag_pos += pos
    # d_context.ag_neg += neg
    # d_context.link_ents += elink
    # d_context.link_res += rlink
    # d_context.user_vals = vals  #  ?
    # d_context.agent_context = actx  # ??


node_fact = NodeFactory.get_instance()

environment_definitions = EnvironmentDefinition.get_instance()


def save_added_objects(added_objects, d_context, d_id, prt=True):
    _, orig_pr, orig_pl, _, _, _, _, _ = get_stub_data_from_json(d_context.init_stub_file)
    if prt:
        print('Inserted to DB: %s' % d_id + '=' * 80)
    added_pr, added_ev, added_pl = [], [], []
    for p in d_context.db_people:
        if p.id not in [i.id for i in orig_pr]:  # any person not in the original stub_DB
            added_pr.append(p)
            if prt:
                print(p)
    for e in d_context.db_events:
        if e.id in d_context.populated_events:  # only events by 'populate' (i.e. not ones by CreateEvent)
            added_ev.append(e)
            if prt:
                print(e)
    for p in d_context.db_places:
        if p.id not in [i.id for i in orig_pl]:  # any place not in the original stub_DB
            added_pl.append(p)
            if prt:
                print(p)
    added_objects[d_id] = (added_pr, added_ev, added_pl)


# execute the pexp
# returns False if an unintended error happened, else True
def exec_turn(pexp, d_context, user_txt, agent_txt, fout=None, cont=False):
    try:
        igl, ex = construct_graph(pexp, d_context, constr_tag=OUTLINE_SIMP, no_post_check=True, no_exit=True)
        gl, ex = trans_graph(igl, add_yield=True)
        check_constr_graph(gl)
        add_turn_entities(user_txt, agent_txt, gl, d_context)
        # implicit accept...?
        # evaluate graph
        if ex is None:
            ex = evaluate_graph(gl)  # send in previous graphs (before curr_graph added)

        # unless a continuation turn, save last exception (agent's last message + hints)
        d_context.set_prev_agent_turn(ex)
        if not cont:
            d_context.inc_turn_num()
        check_dangling_nodes(d_context)  # sanity check - debug only
        if ex:
            if fout:
                fout.write("EXC: %s\n" % to_list(ex)[0].message)
            else:
                print("EXC: %s" % to_list(ex)[0].message)
        elif gl.typename() == 'Yield' and gl.evaluated:
            m = gl.inputs['output'].yield_msg()
            s, o = m.text, m.objects  # y if isinstance(y, tuple) and len(y)==2 else (y, [-999])  # temp check, until all yields return objs
            if fout:
                fout.write('YIELD: %s\n' % s)
            else:
                print('YIELD: %s' % s)
        return True
    except Exception as ex:
        msg = '----------' if len(ex.args) < 1 else '-----===-----' + ex.args[0]
        if fout:
            logger.info(msg)
            fout.write(msg + '\n')
        else:
            print(msg)
        if False and not isinstance(ex, DFException):
            re_raise_exc(ex)
        return True if isinstance(ex, DFException) else False


def gen_turn_logs(user_txt, agent_txt, turn, it, d_id, fout, jout):
    tt = user_txt + ' : [' + agent_txt + ']  '
    fout.write('Turn %d : Dialog %s\n' % (it, d_id))
    fout.write(user_txt + '\n')
    fout.write(turn + '\n')
    fout.write('-AgentAnswer- ' + agent_txt + '\n')
    jout.write(agent_txt + '\n')
    print('\nTurn %d: %s\n' % (it, tt))
    logger.info(turn)


def loc_id_to_name(id, places):
    for l in places:
        for p in l:
            if p.id==id:
                return p.name
    return None

def get_max_id(lol=[]):
    return max([i.id if i.id else 0 for l in lol for i in l]) + 1


def get_decoys(context, apeople, aevents, aplaces, dpeople, devents, dplaces):
    from datetime import datetime, timedelta
    from opendf.applications.core.nodes.time_nodes import datetime_to_domain_str
    from opendf.applications.smcalflow.nodes.objects import check_event_possible
    from opendf.applications.smcalflow.domain import DBevent, DBPerson, WeatherPlace
    npeople, nevents, nplaces = [], [], []
    db_events, db_persons, weather_places, _, CURRENT_RECIPIENT_ID, CURRENT_RECIPIENT_LOCATION_ID, _, _ \
        = get_stub_data_from_json(context.init_stub_file)
    while not npeople and not nevents and not nplaces:
        i = random()
        if i<0.2:  # person
            pass
        elif i<0.3:  # place
            id = get_max_id([weather_places, aplaces, dplaces])
            nm = 'new_room%d' % id
            pl = WeatherPlace(id, nm, '?', None, None, 5, False, False)
            print('= = = added place ', pl)
            nplaces.append(pl)
        else:  # event
            if aevents:
                k = randint(0,len(aevents)-1)
                # DBevent :  ['id', 'subject', 'start', 'end', 'location', 'attendees', 'accepted', 'showas']
                id, subj, start, end, loc, atts, acc, shw = aevents[k]
                id = get_max_id([db_events, aevents, devents])
                # i = randint(0,5)
                if random()<0.5: # subject
                    subj = 's' + str(randint(1,100))
                if random()<0.5:  # shift time
                    dlt = timedelta(hours=randint(0,200) - 100, minutes=15*randint(0,3))
                    st = datetime(*[int(i) for i in start.split('/')]) + dlt
                    en = datetime(*[int(i) for i in end.split('/')]) + dlt
                    start = datetime_to_domain_str(st)
                    end = datetime_to_domain_str(en)
                if random()<0.5:  # location
                    if random()<0.5 or not aplaces:
                        ii = randint(0, len(weather_places) - 1)
                        loc= weather_places[ii].id
                    else:
                        ii = randint(0, len(aplaces) - 1)
                        loc = aplaces[ii].id
                if random()<0.5:  # attendees
                    atts, acc, shw = [CURRENT_RECIPIENT_ID], ['Accepted'], ['Busy']
                    for i in range(randint(0,3)):
                        j = random()
                        if j<0.5 or not apeople:
                            p = db_persons[randint(0, len(db_persons) - 1)].id
                        else:
                            p = apeople[randint(0, len(apeople) - 1)].id
                        if p not in atts:
                            atts.append(p)
                            acc.append('Accepted')
                            shw.append('Busy')
                # check if event is possible
                if check_event_possible(atts, start, end, loc_id_to_name(loc, [weather_places, aplaces])):
                    ev = DBevent(id, subj, start, end, loc, atts, acc, shw)
                    print('= = = add event:', ev)
                    nevents.append(ev)
    return npeople, nevents, nplaces


def dialog(working_dir, inp_name, data_file, dialog_id=None, draw_graph=True, from_id=False, parser_only=False):
    #d_context = DialogContext()
    d_context = PopContext()
    # a_context = DialogContext()

    conv_dir = os.path.join(working_dir, 'conv')
    in_file = os.path.join(working_dir, "conv", f"conv.{inp_name}.jsonl")

    dialogs = load_jsonl_file(in_file, unit=" dialogues")

    # these are log files for debugging / stats
    fout = open(os.path.join(conv_dir, f"db.{inp_name}"), 'w')
    jout = open(os.path.join(conv_dir, f"pop2.{inp_name}"), 'w')
    # lout = open(os.path.join(conv_dir, f"pop1.{inp_name}"), 'w')
    # eout = open(os.path.join(conv_dir, f"err.{inp_name}.conv"), 'w')

    # templates = [i.strip() for i in open(os.path.join(conv_dir, "p1.templ2"), 'r').readlines()]  # needed?

    test_hyps = False  # remove !  (this should be a separate main function, not part of populate_db!)
    if test_hyps:   # test execution of translated pexps
        l = open(os.path.join(conv_dir, f"{inp_name}_hyps.txt"), 'r').readlines()
        hyps = {}
        for i in l:
            j = i.strip().split('::')
            hyps[j[0].strip()] = j[1].strip()

    added_objects = {}  # collect added objects per dialog  TODO - may also include current_user_id, "here"
    stop = False
    n_dia, n_ok = 0,0
    n_turns, n_parse_ok = 0, 0
    for idia, dia in enumerate(dialogs):
        d_id = dia['dialogue_id']
        if dialog_id:
            if d_id[-len(dialog_id):]==dialog_id:  # dialog_id suffix
                if from_id:
                    dialog_id = None
                else:
                    stop = True
            else:
                if stop:  # no need to continue
                    break
                else:
                    continue

        print('\n\n%d %s   '% (idia, d_id) + 'X'*80 + ' \n\n')
        turns = [i['lispress'] for i in dia['turns']]
        accum_text = ''
        d_context.clear()
        d_context.clear_pop_context()
        d_context.prev_nodes = None  # clear prev nodes at start of dialog
        d_context.suppress_exceptions = True  # avoid exit in
        d_context.init_stub_file = data_file

        # d_context.tamplates = templates
        # a_context.clear()
        # a_context.prev_nodes = None  # clear prev nodes at start of dialog
        # a_context.suppress_exceptions = True  # avoid exit in

        # phase 1. with an empty db, go over dialog turns and populate db
        environment_definitions.populating_db = True  # auto-populate db with new objects
        init_db(d_context, data_file=data_file)
        ok = True
        for it, turn in enumerate(turns):
            n_turns += 1
            if ok:
                pexp = turn  # , org = prep_turn(turn)
                user_txt = dia['turns'][it]['user_utterance']['original_text']
                agent_txt = dia['turns'][it]['agent_utterance']['original_text']
                if parser_only:
                    prs, alg = parse_agent_txt(agent_txt)
                    # Note - we don't really need all agent utters to successfully parse!
                    #  but for debugging it can be helpful to look at those which failed
                    print('Agent:: ' + agent_txt + '  :  %s' % ('OK' if prs else 'Fail'))
                    n_parse_ok += 1 if prs else 0
                else:
                    accum_text += 'User- %s  NL  Agent- %s  NL  ' % (user_txt, agent_txt)
                    gen_turn_logs(user_txt, agent_txt, turn, it, d_id, fout, jout)  # do some printouts / log file writes
                    ok = exec_turn(pexp, d_context, user_txt, agent_txt, fout)

        if ok and not parser_only:
            save_added_objects(added_objects, d_context, d_id)

            # phase 2. get execution results using the fully populated db
            #   (in phase 1, earlier turns may not have seen the whole info)
            environment_definitions.populating_db = False  # avoid auto-populating db (decoy objects are added explicitly)
            aobjs = added_objects[d_id]
            apeople, aevents, aplaces = aobjs[0], aobjs[1], aobjs[2]  # the objects which were added
            turn_contexts = []  # contexts after each turn
            turn_evs = []  # db events after each turn
            d_context.clear()
            d_context.clear_pop_context()
            d_context.prev_nodes = None  # clear prev nodes at start of dialog
            d_context.suppress_exceptions = True  # avoid exit in
            init_db(d_context, data_file=data_file, additional_objs=(apeople, aevents, aplaces))
            for it, turn in enumerate(turns):
                if ok:
                    pexp = turn  # , org = prep_turn(turn)
                    user_txt = dia['turns'][it]['user_utterance']['original_text']
                    agent_txt = dia['turns'][it]['agent_utterance']['original_text']
                    ok = exec_turn(pexp, d_context, user_txt, agent_txt, fout)
                    turn_contexts.append(d_context.make_copy_with_pack())  # save d_context after each turn
                    # turn_evs.append(get_all_db_events())  # save all events in db after each turn

            if ok:
                # phase 3. with the populated db, re-run the dialog (without adding objects), verify we get comparable results
                dpeople, devents, dplaces = [], [], []  # the decoy objects
                for i_decoy in range(2):
                    print('/' * 50)
                    #  now - loop: create new object(s?) add to temp db and check if execution is still comparable
                    d_context.clear()
                    d_context.clear_pop_context()
                    d_context.prev_nodes = None  # clear prev nodes at start of dialog
                    d_context.suppress_exceptions = True  # avoid exit in
                    d_context.init_stub_file = data_file
                    npeople, nevents, nplaces = get_decoys(d_context, apeople, aevents, aplaces, dpeople, devents, dplaces)

                    # TODO - instead of init - use add/delete  person/event/place
                    init_db(d_context, data_file=data_file,
                            additional_objs=(apeople+dpeople+npeople, aevents+devents+nevents, aplaces+dplaces+nplaces))
                    cmp = True
                    for it, turn in enumerate(turns):
                        print(turn)
                        pexp = turn.strip()
                        if test_hyps:   # remove !
                            ii = '%s_%d' %(d_id, it)
                            if ii in hyps:
                                if pexp!=hyps[ii]:
                                    print('  >>> .%s.\n    > .%s.' %(pexp, hyps[ii]))
                                pexp = hyps[ii]
                        user_txt = dia['turns'][it]['user_utterance']['original_text']
                        agent_txt = dia['turns'][it]['agent_utterance']['original_text']
                        exec_turn(pexp, d_context, user_txt, agent_txt)

                        # compare context and saved turn contexts
                        ok = compare_graph_exec(d_context, turn_contexts[it])  # added decoys, so don't compare dbevs
                        if not ok:
                            cmp = False

                    if cmp:  # accept
                        dpeople += npeople
                        devents += nevents
                        dplaces += nplaces
                        print('>>>>> Accept!')
                    else:  # reject
                        print('>>>>> Reject!')

                # finally, add the decoys to the added objects
                added_objects[d_id] = (apeople+dpeople, aevents+devents, aplaces+dplaces)

                # TODO - save "ground truth" for dialog - at a minimum, the id's of the objects found by refer/revise
                #        - maybe also the whole graph?? (e.g. save the (compressed) context?)
                #    - how do we evaluate that an execution is correct?
                #      - turn by turn?
                #      - compare results only (which result?), or just agent reply? or also intermediate steps?
                #      - only say match/no match? or also point to what went wrong (e.g. refer)?
                #      - separately count correct refers? (like in paper...)

                # TODO - add decoys!
                #  - after the necessary objects have been added, now try adding some more "close" objects, one at a time
                #    and make sure the result of the dialog does not change (compared to ground truth)

                if dialog_id:
                    if draw_graph:
                        draw_all_graphs(d_context, dialog_id, txt=accum_text)

        n_dia, n_ok = n_dia+1, n_ok+1 if ok else n_ok
        if parser_only:
            print('<%d/%d>' % (n_parse_ok, n_turns))
        else:
            print('<%d/%d>' % (n_ok, n_dia))
    fout.close()
    jout.close()

    # save added objects for all dialogs
    if not parser_only:
        open(os.path.join(conv_dir, f"added.{inp_name}"), 'w').write(json.dumps(added_objects))

    return None


def create_arguments_parser():
    """
    Creates the argument parser for the file.

    :return: the argument parser
    :rtype: argparse.ArgumentParser
    """
    parser = argparse.ArgumentParser(
        description="Entry point to transform original S-exps into simplified P-exps.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )

    parser.add_argument(
        "--config", "-c", metavar="config", type=str, required=False, default="resources/populate_smcalflow_config.yaml",
        help="the configuration file for the application"
    )

    parser.add_argument(
        "working_dir", metavar="working_dir", type=str,
        help="the path for the simplification data directory (e.g. '.../smcalflow'). "
             "Under that, there should be two subdirectories: "
             "`data`: this should have the original annotation files downloaded from microsoft's "
             "task_oriented_dialogue_as_dataflow_synthesis GitHub page. This will include two files: "
             "`train.dataflow_dialogues.jsonl` and `valid.dataflow_dialogues.jsonl`. "
             "Make sure to download version V1 of the data! SMCalFlow 1.0 links -> smcalflow.full.data.tgz; and "
             "`conv`: results of the simplification process (and some extra outputs) will go here."
    )

    input_values = ["train", "valid"]
    parser.add_argument(
        '--input_file', '-i', metavar='input_file',
        type=str, required=True, default=None, choices=input_values,
        help=f"the input file of the system, the choices are: {input_values}. "
             "If not set, it will run a dialog from the `opendf/examples/simplify_examples.py` file, "
             "defined by the `dialog_id` argument",
    )

    parser.add_argument(
        "--dialog_id", "-d", metavar="dialog_id", type=str, required=False, default=0,
        help="the dialog id to use, if `input_file` is not provided. "
             "This should be the index of a dialog defined in the `opendf/examples/simplify_examples.py` file"
    )

    # from_id flags signals to iterate STARTING from the given dialog_id (helpful for debugging)
    parser.add_argument(
        "--from_id", "-f", metavar="from_id", type=bool, required=False, default=False,
        help="start processing from the given id. "
    )

    parser.add_argument(
        "--parser_only", "-p", metavar="parser_only", type=bool, required=False, default=False,
        help="test only the parsing of the agent reply - no population of DB! (for debugging only)"
    )

    parser.add_argument(
        "--log", "-l", metavar="log", type=str, required=False, default="DEBUG",
        choices=LOG_LEVELS.keys(),
        help=f"The level of the logging, possible values are: {list(LOG_LEVELS.keys())}"
    )

    parser = add_environment_option(parser)

    return parser


if __name__ == "__main__":
    try:
        parser = create_arguments_parser()
        arguments = parser.parse_args()
        config_log(arguments.log)
        input_arg = arguments.input_file
        work_arg = arguments.working_dir
        id_arg = arguments.dialog_id
        from_id = arguments.from_id
        parser_only = arguments.parser_only
        if arguments.environment:
            environment_definitions.update_values(**arguments.environment)
        application_config = yaml.load(open(arguments.config, 'r'), Loader=yaml.UnsafeLoader)

        environment_class = application_config["environment_class"]
        environment_class.d_context = PopContext()  # only for graphDB
        with environment_class:
            dialog(work_arg, input_arg, environment_class.stub_data_file, dialog_id=id_arg, from_id=from_id, parser_only=parser_only)

    except Exception as e:
        logger.exception(e)
    finally:
        logging.shutdown()


